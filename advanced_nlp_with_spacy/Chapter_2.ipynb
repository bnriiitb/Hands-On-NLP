{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Large-scale data analysis with spaCy\n",
    "\n",
    "* In this chapter, you'll use your new skills to extract specific information from large volumes of text. \n",
    "* You''ll learn how to make the most of spaCy's data structures, and how to effectively combine statistical and rule-based approaches for text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors and semantic similarity\n",
    "* In this lesson, you'll learn how to use spaCy to predict how similar documents, spans or tokens are to each other.\n",
    "* You'll also learn how to use word vectors and how to take advantage of them in your NLP application.\n",
    "\n",
    "### Comparing semantic similarity\n",
    "* spaCy can compare two objects and predict similarity\n",
    "* Doc.similarity(), Span.similarity() and Token.similarity()\n",
    "* Take another object and return a similarity score (0 to 1)\n",
    "* Important: needs a model that has word vectors included, for example:\n",
    "    * âœ… en_core_web_md (medium model)\n",
    "    * âœ… en_core_web_lg (large model)\n",
    "    * ðŸš« NOT en_core_web_sm (small model)\n",
    "    \n",
    "### Example:\n",
    "* Here's an example. Let's say we want to find out whether two documents are similar.\n",
    "* First, we load the medium English model, \"en_core_web_md\".\n",
    "* We can then create two doc objects and use the first doc's similarity method to compare it to the second.\n",
    "* Here, a fairly high similarity score of 0.86 is predicted for \"I like fast food\" and \"I like pizza\".\n",
    "* The same works for tokens.\n",
    "* According to the word vectors, the tokens \"pizza\" and \"pasta\" are kind of similar, and receive a score of 0.7.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity examples (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8018373287411041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# Load a larger model with vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Compare two documents\n",
    "doc1 = nlp(\"I like fast food\")\n",
    "doc2 = nlp(\"I like pizza\")\n",
    "print(doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32624283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "# Compare two tokens\n",
    "doc = nlp(\"I like pizza and pasta\")\n",
    "token1 = doc[2]\n",
    "token2 = doc[4]\n",
    "print(token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity examples (2)\n",
    "* You can also use the similarity methods to compare different types of objects.\n",
    "* For example, a document and a token.\n",
    "* Here, the similarity score is pretty low and the two objects are considered fairly dissimilar.\n",
    "* Here's another example comparing a span â€“ \"pizza and pasta\" â€“ to a document about McDonalds.\n",
    "* The score returned here is 0.61, so it's determined to be kind of similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28162675424923095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "# Compare a document with a token\n",
    "doc = nlp(\"I like pizza\")\n",
    "token = nlp(\"soap\")[0]\n",
    "print(doc.similarity(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.294720206859215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "# Compare a span with a document\n",
    "span = nlp(\"I like pizza and pasta\")[2:5]\n",
    "doc = nlp(\"McDonalds sells burgers\")\n",
    "\n",
    "print(span.similarity(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does spaCy predict similarity?\n",
    "* Similarity is determined using word vectors\n",
    "* Multi-dimensional meaning representations of words\n",
    "* Generated using an algorithm like Word2Vec and lots of text\n",
    "* Can be added to spaCy's statistical models\n",
    "* Default: cosine similarity, but can be adjusted\n",
    "* Doc and Span vectors default to average of token vectors\n",
    "* Short phrases are better than long documents with many irrelevant words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word vectors in spaCy\n",
    "* To give you an idea of what those vectors look like, here's an example.\n",
    "* First, we load the medium model again, which ships with word vectors.\n",
    "* Next, we can process a text and look up a token's vector using the .vector attribute.\n",
    "* The result is a 300-dimensional vector of the word \"banana\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9383564  -2.9524927   1.1866798   0.49744225 -0.11475766  0.804008\n",
      "  0.4672468  -1.1062207   2.9193573   1.800931   -0.31358248  1.1920271\n",
      " -1.2406584  -2.3237133   2.099902   -0.66673994 -0.96991694  0.8316833\n",
      "  0.10666084 -0.42245626  1.6402073   0.95437694  1.2855074  -2.038612\n",
      " -0.7317371  -0.17545497  0.14752543  1.327169    3.2502053  -3.9332502\n",
      "  1.7409098  -0.73711336  1.4852796  -2.8246899  -1.8938334  -1.2638527\n",
      "  5.298433   -1.2850044  -2.7470415  -1.5607052   5.181785    2.242096\n",
      " -2.1922808  -5.310454    1.0295098   1.484088   -1.5894104  -0.14745024\n",
      "  1.7829046   1.8879583   4.152973   -3.1493165  -0.18937713  2.09369\n",
      " -2.1269834   0.63290507  2.6979058   1.800016   -2.3953576   2.54901\n",
      "  1.0445759  -1.3137031   2.4631662  -0.07756937 -1.129545    0.1169464\n",
      "  1.3869805   0.53586185 -2.242661    2.8641388  -3.8719153  -0.6409143\n",
      "  0.6971829   4.484493   -1.6210997   2.494869    0.7218447  -3.3112261\n",
      " -0.2163549  -2.5339773  -1.1702836  -0.9627162  -3.7210062   1.5599163\n",
      " -1.8974628   1.4590962  -1.8888438   0.19177747 -1.6627836  -2.7840474\n",
      " -0.76189506 -0.2788751   1.743672   -1.8110999   1.5651491   1.7505348 ]\n"
     ]
    }
   ],
   "source": [
    "# Load a larger model with vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"I have a banana\")\n",
    "# Access the vector via the token.vector attribute\n",
    "print(doc[3].vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity depends on the application context\n",
    "* Useful for many applications: recommendation systems, flagging duplicates etc.\n",
    "* There's no objective definition of \"similarity\"\n",
    "* Depends on the context and what application needs to do\n",
    "\n",
    "Predicting similarity can be useful for many types of applications. For example, to recommend a user similar texts based on the ones they have read. It can also be helpful to flag duplicate content, like posts on an online platform.\n",
    "\n",
    "However, it's important to keep in mind that there's no objective definition of what's similar and what isn't. It always depends on the context and what your application needs to do.\n",
    "\n",
    "Here's an example: spaCy's default word vectors assign a very high similarity score to \"I like cats\" and \"I hate cats\". This makes sense, because both texts express sentiment about cats. But in a different application context, you might want to consider the phrases as very dissimilar, because they talk about opposite sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849750871465223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"I like cats\")\n",
    "doc2 = nlp(\"I hate cats\")\n",
    "\n",
    "print(doc1.similarity(doc2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
